#!/usr/bin/env python3
"""
smart_loop_trimmer.py
Detects and removes "return to start" frames from AI-generated loops
to create smoother concatenation by eliminating the jarring reset.
"""

import json, os, subprocess, sys
from pathlib import Path
import cv2
import numpy as np

FFMPEG = os.getenv("FFMPEG", "ffmpeg")
SIMILARITY_THRESHOLD = 0.85  # How similar last frame must be to first frame to detect loop
TRIM_SAFETY_MARGIN = 0.5     # Extra seconds to trim beyond detected loop point

def die(msg, code=2):
    sys.stderr.write(msg + "\n")
    sys.exit(code)

def extract_frame(video_path, timestamp, output_path):
    """Extract a single frame at specified timestamp"""
    cmd = [
        FFMPEG, "-hide_banner", "-loglevel", "error", "-y",
        "-ss", str(timestamp), "-i", str(video_path),
        "-frames:v", "1", str(output_path)
    ]
    subprocess.run(cmd, check=True)

def calculate_frame_similarity(frame1_path, frame2_path):
    """Calculate similarity between two frames using histogram comparison"""
    try:
        img1 = cv2.imread(str(frame1_path))
        img2 = cv2.imread(str(frame2_path))
        
        if img1 is None or img2 is None:
            return 0.0
        
        # Convert to HSV for better color comparison
        hsv1 = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)
        hsv2 = cv2.cvtColor(img2, cv2.COLOR_BGR2HSV)
        
        # Calculate histograms
        hist1 = cv2.calcHist([hsv1], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])
        hist2 = cv2.calcHist([hsv2], [0, 1, 2], None, [50, 60, 60], [0, 180, 0, 256, 0, 256])
        
        # Compare histograms
        similarity = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
        return max(0.0, similarity)
    except Exception:
        return 0.0

def detect_loop_point(video_path, duration):
    """
    Detect where the video starts returning to the beginning frame
    Returns the timestamp where to cut the video for smooth looping
    """
    temp_dir = Path("temp_frames")
    temp_dir.mkdir(exist_ok=True)
    
    try:
        # Extract first frame
        first_frame = temp_dir / "first.jpg"
        extract_frame(video_path, 0.1, first_frame)  # 0.1s to avoid black frames
        
        # Check frames in reverse from the end to find where loop starts
        best_cut_point = duration * 0.8  # Default: cut at 80% if no loop detected
        highest_similarity = 0.0
        
        # Sample frames from 50% to 95% of video duration
        start_check = duration * 0.5
        end_check = duration * 0.95
        step = 0.2  # Check every 0.2 seconds
        
        current_time = end_check
        while current_time > start_check:
            test_frame = temp_dir / f"test_{current_time:.1f}.jpg"
            try:
                extract_frame(video_path, current_time, test_frame)
                similarity = calculate_frame_similarity(first_frame, test_frame)
                
                if similarity > highest_similarity:
                    highest_similarity = similarity
                    if similarity > SIMILARITY_THRESHOLD:
                        best_cut_point = current_time - TRIM_SAFETY_MARGIN
                        break
                
                test_frame.unlink()  # Clean up
            except Exception:
                pass
            
            current_time -= step
        
        # Clean up temp files
        for f in temp_dir.glob("*.jpg"):
            f.unlink()
        temp_dir.rmdir()
        
        # Ensure we don't cut too much
        best_cut_point = max(best_cut_point, duration * 0.6)  # Keep at least 60%
        best_cut_point = min(best_cut_point, duration * 0.9)  # Cut at most 10%
        
        return best_cut_point, highest_similarity
        
    except Exception as e:
        print(f"Error detecting loop in {video_path}: {e}")
        return duration * 0.8, 0.0

def get_video_duration(video_path):
    """Get video duration using ffprobe"""
    try:
        cmd = [
            "ffprobe", "-v", "quiet", "-show_entries", "format=duration",
            "-of", "default=nokey=1:noprint_wrappers=1", str(video_path)
        ]
        result = subprocess.run(cmd, capture_output=True, text=True)
        return float(result.stdout.strip())
    except Exception:
        return 5.0  # Default duration

def process_smart_manifest_with_loop_detection(manifest_path, out_dir):
    """Process smart manifest and add loop detection trimming"""
    
    with open(manifest_path, 'r', encoding='utf-8') as f:
        manifest_data = json.load(f)
    
    items = manifest_data.get("items", [])
    if not items:
        die("No items in manifest")
    
    print("Detecting AI loop points for smoother concatenation...")
    
    processed_items = []
    total_saved_time = 0.0
    
    for i, item in enumerate(items):
        video_path = item.get("path")
        if not video_path or not os.path.exists(video_path):
            continue
        
        # Get original duration
        original_duration = get_video_duration(video_path)
        
        # Detect loop point
        cut_point, similarity = detect_loop_point(video_path, original_duration)
        
        # Update item with new duration
        new_item = item.copy()
        new_item["original_duration"] = original_duration
        new_item["trimmed_duration"] = cut_point
        new_item["loop_similarity"] = similarity
        new_item["t1"] = new_item["t0"] + cut_point
        
        trimmed_amount = original_duration - cut_point
        total_saved_time += trimmed_amount
        
        status = "LOOP DETECTED" if similarity > SIMILARITY_THRESHOLD else "STATIC CUT"
        print(f"  {Path(video_path).name}: {original_duration:.1f}s â†’ {cut_point:.1f}s "
              f"(trim {trimmed_amount:.1f}s) [{status}, sim: {similarity:.3f}]")
        
        processed_items.append(new_item)
    
    # Update manifest
    manifest_data["items"] = processed_items
    manifest_data["loop_detection"] = {
        "total_clips": len(processed_items),
        "total_time_saved": total_saved_time,
        "similarity_threshold": SIMILARITY_THRESHOLD
    }
    
    # Save updated manifest
    loop_manifest_path = out_dir / "smart_manifest_loop_trimmed.json"
    with open(loop_manifest_path, 'w', encoding='utf-8') as f:
        json.dump(manifest_data, f, indent=2)
    
    print(f"\nLoop detection complete:")
    print(f"  Total time saved: {total_saved_time:.1f}s")
    print(f"  Average per clip: {total_saved_time/len(processed_items):.1f}s")
    print(f"  Updated manifest: {loop_manifest_path}")
    
    return loop_manifest_path

def create_trimmed_video(manifest_path, out_dir):
    """Create final video using loop-trimmed clips"""
    
    with open(manifest_path, 'r', encoding='utf-8') as f:
        manifest_data = json.load(f)
    
    items = manifest_data.get("items", [])
    if not items:
        die("No items in manifest")
    
    print(f"\nCreating video with {len(items)} loop-trimmed clips...")
    
    # Build FFmpeg inputs and filters
    inputs = []
    filter_parts = []
    
    for i, item in enumerate(items):
        video_path = item.get("path")
        trimmed_duration = item.get("trimmed_duration", 5.0)
        
        inputs.extend(["-i", str(video_path)])
        
        # Trim to detected loop point and normalize
        filter_parts.append(
            f"[{i}:v]trim=duration={trimmed_duration},setpts=PTS-STARTPTS[v{i}]"
        )
    
    # Concatenate all trimmed clips
    v_inputs = "".join([f"[v{i}]" for i in range(len(items))])
    filter_parts.append(f"{v_inputs}concat=n={len(items)}:v=1:a=0[v]")
    
    filter_complex = ";".join(filter_parts)
    
    # Output file
    output_mp4 = out_dir / "combined_smooth_loops.mp4"
    
    # Build FFmpeg command
    cmd = [
        FFMPEG, "-y"
    ] + inputs + [
        "-filter_complex", filter_complex,
        "-map", "[v]",
        "-c:v", "libx264", "-preset", "veryfast", "-crf", "20", "-pix_fmt", "yuv420p",
        str(output_mp4)
    ]
    
    print(f"Generating: {output_mp4.name}")
    
    # Execute
    proc = subprocess.run(cmd, text=True, capture_output=True)
    
    if proc.returncode != 0:
        print("FFmpeg error:")
        print(proc.stderr[-1000:])
        die("FFmpeg failed", proc.returncode)
    
    print(f"\nSuccess! Created smooth-flow video: {output_mp4}")
    
    # Summary
    total_duration = sum(item.get("trimmed_duration", 5.0) for item in items)
    total_saved = manifest_data.get("loop_detection", {}).get("total_time_saved", 0)
    
    print(f"\nSummary:")
    print(f"  Final duration: {total_duration:.1f}s")
    print(f"  Time saved by trimming loops: {total_saved:.1f}s")
    print(f"  Clips processed: {len(items)}")
    print(f"  Result: Smoother flow without AI loop resets")

def main():
    if len(sys.argv) < 2:
        die(f"Usage: {sys.argv[0]} <OUT_DIR>")
    
    out_dir = Path(sys.argv[1]).resolve()
    
    # Look for smart manifest
    smart_manifest = out_dir / "smart_manifest.json"
    if not smart_manifest.exists():
        die(f"Smart manifest not found: {smart_manifest}")
    
    print("AI Loop Trimmer - Removing return-to-start frames for smoother flow")
    print("=" * 60)
    
    # Process manifest with loop detection
    loop_manifest = process_smart_manifest_with_loop_detection(smart_manifest, out_dir)
    
    # Create final video
    create_trimmed_video(loop_manifest, out_dir)

if __name__ == "__main__":
    main()
